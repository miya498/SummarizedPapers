# IllusionVQA: 視覚と言語モデル向け光学的錯視データセット

## 概要
Vision-Languageモデル（VLM）の進化により、自然言語を用いたニューラルネットワークの視覚理解が可能になった。これにより、画像が本質的に不合理な場合にVLMがどのように反応するかを調査する新たな課題が生じた。本研究では、光学的錯視や解釈が困難なシーンを含む多様なデータセット「IllusionVQA」を提案する。このデータセットは以下の二つのタスクで構成される：

1. **理解タスク（Comprehension）**  
   複数選択式の質問形式で錯視の内容を問う。
2. **ソフトローカリゼーションタスク（Soft Localization）**  
   幾何学的に不可能なオブジェクトを識別する能力を評価する。

実験結果では、GPT-4Vが最も高い性能を示したが、人間の精度（理解タスク：91.03%、ローカリゼーションタスク：100%）には及ばなかった。また、VLMの「In-Context Learning（ICL）」と「Chain-of-Thought（CoT）」推論がローカリゼーションタスクで性能を低下させることを発見した。

---

## 1. はじめに
光学的錯視は、現実とは異なる視覚認知をもたらす現象であり、分類が困難である。例として、不可能な図形や色の錯視などがある。これらの錯視に対するVLMの認知能力を検証するため、「IllusionVQA」というデータセットを構築した。

### IllusionVQAの特徴
- **多様なカテゴリ**: 12種類の錯視カテゴリ（例：不可能な物体、隠れた形状、色錯視など）。
- **質問形式**: 人間とVLMの理解を比較可能な複数選択式。

---

## 2. IllusionVQAデータセット

### データ収集とフィルタリング
- インターネットから3,500以上の錯視画像を収集し、手動で374枚を選別。
- 選別基準には、GPT-4Vによる錯視認識能力の評価が含まれる。

### 質問生成
- 各錯視画像に対して1つの正答と複数の誤答を含む質問を作成。
- 質問は曖昧さを排除し、正答が明確になるよう工夫。

---

## 3. 実験設定と結果

### 実験設定
- VLMは、0-shotと4-shot設定で評価。
- 人間の評価も行い、比較のためにWebインターフェースを使用。

### 主な結果
1. **理解タスク**  
   - GPT-4Vは62.99%の精度を達成したが、人間（91.03%）には及ばず。
   - サイズや色の錯視カテゴリで他モデルより優れるが、全体的な理解は不十分。
2. **ローカリゼーションタスク**  
   - 幾何学的に不可能なオブジェクトの特定では、GPT-4Vが49.7%と低精度。
   - 人間の100%と比較して、大きな差がある。

---

## 4. 議論

### VLMの課題
- **言語バイアス**: 文脈例に依存する傾向があり、視覚情報を無視することがある。
- **空間推論の弱さ**: 幾何学的錯視の認識には課題が残る。

### 応用可能性
ロボティクスやリアルワールドアプリケーションでの利用には、錯視に強いVLMが求められる。

---

## 5. 結論
本研究では、光学的錯視を理解・特定する能力をVLMで検証し、限界を明らかにした。IllusionVQAデータセットと評価コードは公開されており、さらなる研究の発展を目指している。

**限界と今後の課題**
- データセットの規模が限られている。
- 開放型質問形式の評価が未実施。

**リソース**  
データセットとコードは[GitHubリポジトリ](https://github.com/csebuetnlp/IllusionVQA)で公開。
